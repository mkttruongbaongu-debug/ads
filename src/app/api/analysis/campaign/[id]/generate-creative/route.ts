/**
 * ===================================================================
 * API: GENERATE CREATIVE (Caption + Image) ‚Äî STREAMING
 * ===================================================================
 * Route: POST /api/analysis/campaign/[id]/generate-creative
 *
 * Input: Creative Brief + Top Ads data
 * Output: NDJSON Stream ‚Äî caption first, then images one-by-one
 *
 * Pipeline:
 * 1. Gemini 2.5 Flash ‚Üí Caption + Image Prompt
 * 2. Gemini 3 Pro Image Preview ‚Üí Generate images (streamed 1 by 1)
 * ===================================================================
 */

import { NextRequest } from 'next/server';
import OpenAI from 'openai';

// Extend serverless timeout (Vercel/Netlify)
export const maxDuration = 300; // 5 minutes

// ===================================================================
// STEP 1: GENERATE CAPTION + IMAGE PROMPT (Gemini 2.5 Flash)
// ===================================================================

function buildCaptionPrompt(briefData: any, referenceImageCount?: number, referenceImageUrls?: string[]): string {
    const { creativeBrief, winningPatterns, topAds, campaignName, genMode, winnerCaption } = briefData;
    const mode = genMode || 'inspired';

    // Mode-specific mission description
    let missionBlock = '';
    if (mode === 'clone' && winnerCaption) {
        missionBlock = `## CH·∫æ ƒê·ªò: NH√ÇN B·∫¢N (SPIN)
‚ö†Ô∏è B·∫ÆT BU·ªòC: SPIN caption g·ªëc b√™n d∆∞·ªõi.
GI·ªÆ NGUY√äN: nh·ªãp c√¢u, tone, CTA, ƒë·ªô d√†i t∆∞∆°ng ƒë∆∞∆°ng.
ƒê·ªîI: t·ª´ ng·ªØ kh√°c (paraphrase), chi ti·∫øt c·ª• th·ªÉ kh√°c.

CAPTION G·ªêC C·∫¶N SPIN:
"""
${winnerCaption}
"""

Image prompts ph·∫£i MATCH n·ªôi dung caption m·ªõi.`;
    } else if (mode === 'fresh') {
        missionBlock = `## CH·∫æ ƒê·ªò: S√ÅNG T·∫†O M·ªöI
Vi·∫øt caption HO√ÄN TO√ÄN M·ªöI, g√≥c ti·∫øp c·∫≠n KH√ÅC winning ads.
Ch·ªâ d·ª±a tr√™n Creative Brief + th√¥ng tin s·∫£n ph·∫©m.`;
    } else {
        // inspired (default)
        missionBlock = `## CH·∫æ ƒê·ªò: L·∫§Y C·∫¢M H·ª®NG
H·ªçc phong c√°ch winning ads (c√°ch d√πng t·ª´, nh·ªãp c√¢u, c·∫£m x√∫c).
T·∫°o b·∫£n M·ªöI nh∆∞ng GI·ªÆ phong c√°ch ƒë√£ ch·ª©ng minh hi·ªáu qu·∫£.
KH√îNG copy nguy√™n vƒÉn.`;
    }

    if (mode === 'clone') {
        missionBlock += `\n\n‚õî QUY T·∫ÆC S·∫¢N PH·∫®M:
- S·∫£n ph·∫©m caption spin PH·∫¢I GI·ªêNG Y caption g·ªëc
- KH√îNG thay ƒë·ªïi, KH√îNG tr·ªôn l·∫´n s·∫£n ph·∫©m kh√°c
- Image prompts PH·∫¢I m√¥ t·∫£ ƒê√öNG s·∫£n ph·∫©m trong caption g·ªëc`;
    }

    const briefBlock = mode === 'clone' ? `## STYLE GUIDELINES
- Caption Guideline: ${creativeBrief?.captionGuideline || 'N/A'}
- Visual Direction: ${creativeBrief?.visualDirection || 'N/A'}
- CTA: ${creativeBrief?.ctaRecommendation || 'N/A'}` : `## CREATIVE BRIEF
- Summary: ${creativeBrief?.summary || 'N/A'}
- Target Audience: ${creativeBrief?.targetAudience || 'N/A'}
- Content Format: ${creativeBrief?.contentFormat || 'N/A'}
- Caption Guideline: ${creativeBrief?.captionGuideline || 'N/A'}
- Visual Direction: ${creativeBrief?.visualDirection || 'N/A'}
- CTA: ${creativeBrief?.ctaRecommendation || 'N/A'}`;

    const captionExamplesBlock = mode === 'clone' ? '' :
        (mode !== 'fresh' && creativeBrief?.captionExamples?.length ? `## CAPTION M·∫™U T·ª™ ADS TH·∫ÆNG
${creativeBrief.captionExamples.map((ex: string, i: number) => `${i + 1}. \"${ex}\"`).join('\n')}` : '');

    const winningPatternsBlock = mode === 'clone' ? '' :
        (mode !== 'fresh' ? `## WINNING PATTERNS
${winningPatterns?.map((p: any) => `- [${p.category}] ${p.pattern} (Evidence: ${p.evidence})`).join('\n') || 'N/A'}` : '');

    const topAdsBlock = mode === 'clone' ? '' :
        (mode !== 'fresh' ? `## TOP ADS TH·∫ÆNG
${topAds?.map((ad: any, i: number) => `- Ad #${i + 1} \"${ad.name}\" (ROAS ${ad.roas?.toFixed(1)}x, CPP ${ad.cpp?.toLocaleString()}): ${ad.whyItWorks}`).join('\n') || 'N/A'}` : '');

    return `B·∫°n l√† copywriter Facebook Vi·ªát Nam ‚Äî chuy√™n vi·∫øt caption T·ª∞ NHI√äN, NG·∫ÆN G·ªåN, ƒë·ªçc nh∆∞ NG∆Ø·ªúI TH·∫¨T chia s·∫ª, KH√îNG PH·∫¢I qu·∫£ng c√°o.

## PHONG C√ÅCH CAPTION B·∫ÆT BU·ªòC

### TRI·∫æT L√ù: "Vi·∫øt nh∆∞ nh·∫Øn tin cho b·∫°n b√®, kh√¥ng vi·∫øt nh∆∞ qu·∫£ng c√°o"

CAPTION PH·∫¢I:
- NG·∫ÆN G·ªåN: T·ªëi ƒëa 5-7 d√≤ng. M·ªói d√≤ng ng·∫Øn, d·ªÖ ƒë·ªçc tr√™n ƒëi·ªán tho·∫°i
- T·ª∞ NHI√äN 100%: Vi·∫øt ƒë√∫ng gi·ªçng n√≥i ƒë·ªùi th∆∞·ªùng c·ªßa ng∆∞·ªùi Vi·ªát (c√≥ th·ªÉ h∆°i xu·ªÅ xo√†, th√¢n m·∫≠t)
- KH√îNG C√ì TI√äU ƒê·ªÄ: Kh√¥ng ‚ú® TI√äU ƒê·ªÄ IN HOA, kh√¥ng --- ph√¢n c√°ch, kh√¥ng bullet points
- HOOK M·∫†NH: 1 c√¢u ƒë·∫ßu ph·∫£i khi·∫øn ng∆∞·ªùi ta d·ª´ng scroll ‚Äî g√¢y t√≤ m√≤, shock nh·∫π, ho·∫∑c ƒë·ªìng c·∫£m
- TH·∫≤NG V√ÄO V·∫§N ƒê·ªÄ: Kh√¥ng d·∫´n d·∫Øt v√≤ng vo, kh√¥ng "B·∫°n c√≥ bao gi·ªù...", kh√¥ng m·ªü b√†i d√†i d√≤ng
- K·∫æT TH√öC G·ªåN: CTA nh·∫π nh√†ng, t·ª± nhi√™n (inbox, comment, ho·∫∑c link) ‚Äî kh√¥ng √©p bu·ªôc

C·∫§U TR√öC L√ù T∆Ø·ªûNG (Alex Hormozi style thu·∫ßn Vi·ªát):
D√≤ng 1: Hook ‚Äî 1 c√¢u g√¢y t√≤ m√≤ / shock nh·∫π / nh·∫≠n ƒë·ªãnh th·∫≥ng
D√≤ng 2-4: Value ‚Äî chia s·∫ª tr·∫£i nghi·ªám / review th·∫≠t / m·∫πo hay (ng·∫Øn, c·ª• th·ªÉ, c√≥ s·ªë li·ªáu n·∫øu ƒë∆∞·ª£c)
D√≤ng 5-6: CTA t·ª± nhi√™n ‚Äî "inbox m√¨nh", "link ·ªü comment", ho·∫∑c th√¥ng tin li√™n h·ªá

‚ùå TUY·ªÜT ƒê·ªêI C·∫§M (n·∫øu vi ph·∫°m = FAIL):
- Caption d√†i h∆°n 10 d√≤ng
- C√≥ ti√™u ƒë·ªÅ / header / ph√¢n c√°ch b·∫±ng emoji d√†n h√†ng (üî•üî•üî•)
- Gi·ªçng ƒëi·ªáu "chuy√™n gia" ho·∫∑c "th∆∞∆°ng hi·ªáu" ‚Äî ph·∫£i l√† gi·ªçng ng∆∞·ªùi th·∫≠t
- M·ªü b√†i ki·ªÉu "B·∫°n ƒë√£ bao gi·ªù...", "Xin ch√†o...", "Gi·ªõi thi·ªáu ƒë·∫øn b·∫°n..."
- Li·ªát k√™ nhi·ªÅu bullet points ‚Äî qu√° qu·∫£ng c√°o
- C√¢u CTA √©p bu·ªôc ki·ªÉu "MUA NGAY", "ƒê·∫∂T H√ÄNG NGAY H√îM NAY", "ƒê·ª™NG B·ªé L·ª†"
- L·∫∑p l·∫°i √Ω ‚Äî m·ªói d√≤ng ph·∫£i c√≥ th√¥ng tin M·ªöI
- Vi·∫øt hoa to√†n b·ªô ƒë·ªÉ nh·∫•n m·∫°nh

‚úÖ V√ç D·ª§ CAPTION CHU·∫®N (tone t·ª± nhi√™n Vi·ªát):
---
Th·ªãt kho t√†u m√† kho ki·ªÉu n√†y th√¨ c∆°m 3 b√°t ch·ª© kh√¥ng ƒë√πa üòÇ

M·∫πo l√† phi h√†nh cho th∆°m tr∆∞·ªõc, rim v·ªè tr·ª©ng tr∆∞·ªõc khi th·∫£ v√†o, n∆∞·ªõc d·ª´a t∆∞∆°i ch·ª© ƒë·ª´ng d√πng n∆∞·ªõc d·ª´a h·ªôp.

ƒÇn n√≥ng v·ªõi c∆°m tr·∫Øng, k√®m d∆∞a leo + canh chua.

Ship Hu·∫ø, inbox m√¨nh nh√©.
---

## NHI·ªÜM V·ª§
${mode === 'clone' ? 'SPIN caption g·ªëc th√†nh caption m·ªõi, gi·ªØ nguy√™n s·∫£n ph·∫©m v√† phong c√°ch.' : 'T·∫°o:'}
1. **Caption** ‚Äî t·ª± nhi√™n, ng·∫Øn g·ªçn, ƒë·ªçc nh∆∞ NG∆Ø·ªúI TH·∫¨T chia s·∫ª
2. **Image prompts CHI TI·∫æT** ‚Äî m√¥ t·∫£ ·∫£nh ki·ªÉu NG∆Ø·ªúI TH·∫¨T CH·ª§P B·∫∞NG ƒêI·ªÜN THO·∫†I (UGC / POV style)

## CHI·∫æN D·ªäCH: ${campaignName}

${missionBlock}

${briefBlock}

${captionExamplesBlock}

${winningPatternsBlock}

${topAdsBlock}

## IMAGE PROMPT REQUIREMENTS

### Phong c√°ch: Xiaohongshu food photography ‚Äî ƒë·∫πp m√† t·ª± nhi√™n

M·ªói image prompt PH·∫¢I ng·∫Øn g·ªçn (50-80 t·ª´ ti·∫øng Anh), t·∫≠p trung v√†o:
1. **Subject**: M√¥ t·∫£ m√≥n ƒÉn ch√≠nh x√°c ‚Äî lo·∫°i, h√¨nh d√°ng, m√†u s·∫Øc, texture th·ª±c t·∫ø
2. **Action**: H√†nh ƒë·ªông ƒëang di·ªÖn ra (tay c·∫ßm ƒë≈©a g·∫Øp, mu·ªóng m√∫c, r√≥t n∆∞·ªõc s·ªët...)
3. **Mood**: T√¥ng m√†u, √°nh s√°ng, c·∫£m gi√°c chung
4. **Context**: B·ªëi c·∫£nh ng·∫Øn g·ªçn (b√†n ƒÉn, qu√°n, b·∫øp nh√†)

### ƒê·ªò CH√çNH X√ÅC V·∫¨T L√ù (C·ª∞C K·ª≤ QUAN TR·ªåNG):
- M√¥ t·∫£ texture th·ª©c ƒÉn ƒê√öNG th·ª±c t·∫ø:
  + C√° s·ªëng/sashimi ‚Üí "semi-translucent, glistening raw flesh, visible grain"
  + Th·ªãt n·∫•u ch√≠n ‚Üí "opaque, caramelized, firm"
  + ƒê·ªì chi√™n ‚Üí "crispy golden crust"
  + N∆∞·ªõc s·ªët ‚Üí "glossy, viscous"
- KH√îNG th√™m steam/kh√≥i cho M√ìN L·∫†NH (sashimi, g·ªèi, salad, ƒë·ªì ng√¢m l·∫°nh, sushi)
- CH·ªà m√¥ t·∫£ steam cho M√ìN N√ìNG (ph·ªü, c∆°m n√≥ng, ƒë·ªì n∆∞·ªõng, l·∫©u)
- M√¥ t·∫£ M√ÄU S·∫ÆC th·ª±c t·∫ø ‚Äî c√° h·ªìi = cam h·ªìng, th·ªãt kho = n√¢u caramel, rau = xanh t∆∞∆°i

### QUY T·∫ÆC VI·∫æT PROMPT CHO SEEDREAM:
- NG·∫ÆN G·ªåN: 50-80 t·ª´. Seedream hi·ªÉu prompt ng·∫Øn t·ªët h∆°n prompt d√†i
- KH√îNG li·ªát k√™ chi ti·∫øt background qu√° c·ª• th·ªÉ (lo·∫°i ƒë√®n, lo·∫°i b√†n, lo·∫°i s√†n)
- KH√îNG n√≥i "NOT AI-generated" ho·∫∑c "NOT stock photo" ‚Äî ch·ªâ m√¥ t·∫£ c√°i B·∫†N MU·ªêN, kh√¥ng n√≥i c√°i kh√¥ng mu·ªën
- KH√îNG n√≥i "phone camera noise" ho·∫∑c "slight blur" ‚Äî Seedream s·∫Ω l√†m ·∫£nh x·∫•u
- T·∫≠p trung m√¥ t·∫£: subject + action + lighting mood + background ng·∫Øn
- Background: "casually busy" ‚Äî c√≥ c√°c ƒëƒ©a kh√°c, gia v·ªã, ly n∆∞·ªõc xung quanh ‚Äî nh∆∞ng b√†n/b·ªÅ m·∫∑t PH·∫¢I S·∫†CH S·∫º, KH√îNG c√≥ v·∫øt b·∫©n, n∆∞·ªõc ƒë·ªï, hay ƒë·ªì b·∫©n

‚ùå C·∫§M trong image prompt:
- Prompt d√†i h∆°n 100 t·ª´
- Li·ªát k√™ 5+ chi ti·∫øt background
- M√¥ t·∫£ camera specs (iPhone 14, Samsung S23...)
- N√≥i "NOT studio", "NOT professional" ‚Äî ch·ªâ n√≥i c√°i mu·ªën th√¥i
- Th√™m steam/kh√≥i cho m√≥n l·∫°nh
- D√πng t·ª´ "messy", "cluttered", "dirty" ‚Äî thay b·∫±ng "casually busy", "lived-in"
- Background b·∫©n, c√≥ v·∫øt ·ªë, n∆∞·ªõc s·ªët v∆∞∆°ng v√£i

‚úÖ V√ç D·ª§ PROMPT CHU·∫®N:
"Xiaohongshu food photo. Hand with chopsticks lifting a piece of semi-translucent soy-marinated salmon sashimi from a dark ceramic bowl. The raw fish glistens with soy sauce and sesame seeds. Warm ambient lighting, shallow depth of field. Clean table with other dishes and condiment bottles in blurred background. Close-up, appetizing. Aspect ratio: 3:4."

S·ªë l∆∞·ª£ng ·∫£nh: ${mode === 'clone' && referenceImageCount ? referenceImageCount : '1, 2, ho·∫∑c 4 (tu·ª≥ content format)'}
${mode === 'clone' && referenceImageCount ? `‚ö†Ô∏è B·∫ÆT BU·ªòC: imageCount PH·∫¢I = ${referenceImageCount} v√† imagePrompts PH·∫¢I c√≥ ƒê√öNG ${referenceImageCount} prompt ri√™ng bi·ªát (m·ªói prompt m√¥ t·∫£ 1 ·∫£nh kh√°c nhau).` : ''}
${referenceImageUrls && referenceImageUrls.length > 0 ? `
## ·∫¢NH THAM KH·∫¢O ƒê√É ƒê√çNH K√àM
‚ö†Ô∏è QUAN TR·ªåNG: ${referenceImageUrls.length} ·∫£nh tham kh·∫£o ƒë√£ ƒë∆∞·ª£c ƒë√≠nh k√®m b√™n d∆∞·ªõi (·∫¢nh tham kh·∫£o #1, #2, ...).
B·∫°n PH·∫¢I vi·∫øt imagePrompts THEO TH·ª® T·ª∞ T∆Ø∆†NG ·ª®NG:
- imagePrompts[0] ‚Üí m√¥ t·∫£ ·∫£nh M·ªöI l·∫•y C·∫¢M H·ª®NG t·ª´ ·∫¢nh tham kh·∫£o #1 (c√πng g√≥c ch·ª•p, b·ªë c·ª•c, s·∫£n ph·∫©m, nh∆∞ng kh√°c chi ti·∫øt)
- imagePrompts[1] ‚Üí m√¥ t·∫£ ·∫£nh M·ªöI l·∫•y C·∫¢M H·ª®NG t·ª´ ·∫¢nh tham kh·∫£o #2
- ... v√† t∆∞∆°ng t·ª± cho c√°c ·∫£nh c√≤n l·∫°i
M·ªói prompt ph·∫£i MATCH v·ªõi ·∫£nh tham kh·∫£o t∆∞∆°ng ·ª©ng ‚Äî nh√¨n ·∫£nh ref r·ªìi m√¥ t·∫£ ·∫£nh m·ªõi gi·ªëng ki·ªÉu ƒë√≥.` : ''}
D√ôNG TI·∫æNG ANH cho image prompt

Tr·∫£ l·ªùi JSON (kh√¥ng markdown, kh√¥ng \`\`\`):
{
  "caption": "N·ªôi dung caption ƒë·∫ßy ƒë·ªß...",
  "imageCount": 1 | 2 | 4,
  "imagePrompts": [
    "Extremely detailed UGC-style smartphone photo prompt... Aspect ratio: 4:5 portrait (1080x1350px)."
  ],
  "keyMessage": "Th√¥ng ƒëi·ªáp ch√≠nh trong 1 c√¢u",
  "inspirationSource": "L·∫•y c·∫£m h·ª©ng ch√≠nh t·ª´ Ad #X (t√™n ad, ROAS Xx) v√¨: l√Ω do"
}`;
}
// ===================================================================
// STEP 2: GENERATE IMAGES (Gemini 3 Pro Image Preview)
// ===================================================================

// X√°c ƒë·ªãnh aspect ratio d·ª±a tr√™n s·ªë l∆∞·ª£ng ·∫£nh t·ªïng
function getAspectRatioSpec(imageCount: number): { ratio: string; resolution: string; instruction: string } {
    switch (imageCount) {
        case 2:
            return { ratio: '4:5', resolution: '1080x1350', instruction: 'PORTRAIT 4:5 aspect ratio (1080x1350px). Two images will display as vertical columns side by side on Facebook feed.' };
        case 4:
            return { ratio: '1:1', resolution: '1080x1080', instruction: 'SQUARE 1:1 aspect ratio (1080x1080px). Four images will display as a 2x2 grid on Facebook feed.' };
        default: // 1 image
            return { ratio: '4:5', resolution: '1080x1350', instruction: 'PORTRAIT 4:5 aspect ratio (1080x1350px). Single image maximizes vertical screen real estate on mobile Facebook feed.' };
    }
}

// Validate if a URL is accessible (quick HEAD check)
async function isUrlAccessible(url: string): Promise<boolean> {
    try {
        const controller = new AbortController();
        const timeout = setTimeout(() => controller.abort(), 5000); // 5s timeout
        const res = await fetch(url, {
            method: 'HEAD',
            signal: controller.signal,
            redirect: 'follow',
        });
        clearTimeout(timeout);
        return res.ok; // 200-299
    } catch {
        return false;
    }
}

// Download image and convert to base64 for inline_data
async function downloadImageAsBase64(url: string): Promise<{ data: string; mimeType: string } | null> {
    try {
        const controller = new AbortController();
        const timeout = setTimeout(() => controller.abort(), 15000); // 15s timeout
        const res = await fetch(url, {
            signal: controller.signal,
            redirect: 'follow',
        });
        clearTimeout(timeout);
        if (!res.ok) return null;
        const contentType = res.headers.get('content-type') || 'image/jpeg';
        const mimeType = contentType.split(';')[0].trim();
        const buffer = await res.arrayBuffer();
        const base64 = Buffer.from(buffer).toString('base64');
        return { data: base64, mimeType };
    } catch {
        return null;
    }
}

async function generateImage(
    apiKey: string,
    prompt: string,
    referenceImageUrl: string | null,
    imageCount: number,
    sendDebug?: (msg: string) => void,
): Promise<string | null> {
    const log = (msg: string) => {
        console.log(msg);
        sendDebug?.(msg);
    };

    // ‚îÄ‚îÄ‚îÄ Download reference image as base64 (OpenRouter/Gemini can't fetch Facebook CDN directly) ‚îÄ‚îÄ‚îÄ
    let refBase64: { data: string; mimeType: string } | null = null;
    if (referenceImageUrl) {
        log(`[IMG] Downloading ref image: ${referenceImageUrl.substring(0, 80)}...`);
        refBase64 = await downloadImageAsBase64(referenceImageUrl);
        if (!refBase64) {
            log(`[IMG] ‚ö†Ô∏è Failed to download ref ‚Üí generating WITHOUT reference`);
        } else {
            log(`[IMG] ‚úÖ Ref downloaded (${Math.round(refBase64.data.length / 1024)}KB, ${refBase64.mimeType})`);
        }
    }

    // ‚îÄ‚îÄ‚îÄ Attempt generation (with retry) ‚îÄ‚îÄ‚îÄ
    for (let attempt = 1; attempt <= 3; attempt++) {
        const useRef = attempt === 1 ? refBase64 : null;
        if (attempt === 2) {
            log(`[IMG] üîÑ RETRY attempt 2 ‚Äî generating WITHOUT reference image`);
        } else if (attempt === 3) {
            log(`[IMG] üîÑ RETRY attempt 3 ‚Äî simplified prompt, no reference`);
        }

        try {
            const aspectSpec = getAspectRatioSpec(imageCount);

            // For attempt 3, simplify the prompt
            const effectivePrompt = attempt === 3
                ? `Generate a high-quality food photography image. ${prompt.substring(0, 200)}. Aspect ratio: ${aspectSpec.ratio} (${aspectSpec.resolution}).`
                : `You are creating an AUTHENTIC smartphone photo that looks like a REAL PERSON took it and posted on social media. This is for a Vietnamese Facebook ad.

CRITICAL IDENTITY: You are NOT a professional photographer. You are a REGULAR PERSON casually taking a quick photo with your phone to share with friends on Facebook. The photo should feel SPONTANEOUS and LIVED-IN.

‚ö†Ô∏è MANDATORY ASPECT RATIO: ${aspectSpec.instruction}
The image MUST be generated in ${aspectSpec.ratio} ratio (${aspectSpec.resolution}). This is NON-NEGOTIABLE.

${useRef ? `REFERENCE IMAGE: The attached image is the ORIGINAL winning ad photo. Your job is to create a NEW photo that:
- Has the SAME composition, angle, and framing as the reference
- Features the SAME type of product/subject in a SIMILAR setting
- Matches the SAME lighting conditions and color temperature
- Keeps the SAME mood and vibe
- But with ENOUGH variation that it looks like a DIFFERENT photo (different angle, slightly different items, etc.)
Think of it as: "Same person, same product, different day, different photo"` : 'No reference image available ‚Äî create based on the prompt description only.'}

PHOTOGRAPHY BRIEF:
${prompt}

=== UGC / POV STYLE REQUIREMENTS (MOST IMPORTANT) ===

MUST HAVE ‚Äî Signs of authenticity:
- Smartphone camera characteristics: slight noise/grain, natural phone lens depth of field
- IMPERFECT composition: subject slightly off-center, slightly tilted horizon, not perfectly framed
- REAL environment clutter: other objects visible (phone, keys, bag, cup, napkins, random items on table)
- NATURAL lighting from the actual environment: overhead fluorescent, window daylight, warm lamp, screen glow ‚Äî whatever is realistic for the setting
- Human presence hints: a hand holding/touching the product, part of an arm, sleeve visible
- The scene should tell a story: someone is IN THE MIDDLE of using/experiencing the product

ABSOLUTELY FORBIDDEN ‚Äî Dead giveaways of fake/staged photos:
- ‚ùå Perfect symmetry or centered composition ‚Äî INSTANT red flag
- ‚ùå Studio lighting, softbox, rim light, any professional lighting setup
- ‚ùå Clean/empty/minimalist background ‚Äî real life is messy
- ‚ùå Product floating on solid color background ‚Äî that's e-commerce, not UGC
- ‚ùå Professional food/product styling with artistic garnish placement
- ‚ùå DSLR/mirrorless camera quality (too sharp, too perfect bokeh)
- ‚ùå Perfectly white-balanced, color-corrected look
- ‚ùå Any text, watermarks, logos, or overlays
- ‚ùå Surreal, fantasy, or obviously AI-generated elements
- ‚ùå "Magazine cover" or "editorial" aesthetic

THE ULTIMATE TEST: If someone scrolling Facebook would pause and think "this looks like a real person posted this, not an ad" ‚Äî you succeeded.

OUTPUT: A single authentic-looking smartphone photo in ${aspectSpec.ratio} aspect ratio.`;

            const contentParts: any[] = [
                { type: 'text', text: effectivePrompt },
            ];

            if (useRef) {
                contentParts.push({
                    type: 'image_url',
                    image_url: { url: `data:${useRef.mimeType};base64,${useRef.data}` },
                });
            }

            log(`[IMG] Calling OpenRouter (attempt ${attempt}, ref=${useRef ? 'YES' : 'NO'})...`);

            // ‚îÄ‚îÄ‚îÄ Use stream: true ‚Äî OpenRouter always streams image gen anyway ‚îÄ‚îÄ‚îÄ
            const TIMEOUT_MS = 120_000;
            const abortCtrl = new AbortController();
            const timer = setTimeout(() => abortCtrl.abort(), TIMEOUT_MS);

            const rawRes = await fetch('https://openrouter.ai/api/v1/chat/completions', {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                    'Authorization': `Bearer ${apiKey}`,
                    'HTTP-Referer': 'https://ads.supbaongu.vn',
                    'X-Title': 'THO ADS AI - Creative Studio',
                },
                body: JSON.stringify({
                    model: 'google/gemini-3-pro-image-preview',
                    messages: [{ role: 'user', content: contentParts }],
                    modalities: ['image', 'text'],
                    stream: true,
                }),
                signal: abortCtrl.signal,
            });
            clearTimeout(timer);

            log(`[IMG] Response status: ${rawRes.status}, content-type: ${rawRes.headers.get('content-type')}`);

            if (!rawRes.ok) {
                const errText = await rawRes.text().catch(() => '');
                log(`[IMG] ‚ùå OpenRouter HTTP ${rawRes.status}: ${errText.substring(0, 300)}`);
                throw new Error(`OpenRouter HTTP ${rawRes.status}`);
            }

            // ‚îÄ‚îÄ‚îÄ Read SSE stream chunk by chunk ‚îÄ‚îÄ‚îÄ
            const reader = rawRes.body?.getReader();
            if (!reader) throw new Error('No response body reader');

            const decoder = new TextDecoder();
            let buffer = '';
            let accumulatedContent = '';
            const accumulatedImages: any[] = [];
            let lastFinishReason = '';
            let chunkCount = 0;

            while (true) {
                const { done, value } = await reader.read();
                if (done) break;

                buffer += decoder.decode(value, { stream: true });
                const lines = buffer.split('\n');
                buffer = lines.pop() || '';

                for (const line of lines) {
                    const trimmed = line.trim();
                    if (!trimmed.startsWith('data: ')) continue;
                    const data = trimmed.substring(6);
                    if (data === '[DONE]') continue;

                    try {
                        const chunk = JSON.parse(data);
                        chunkCount++;
                        const choice = chunk?.choices?.[0];
                        const delta = choice?.delta;
                        if (choice?.finish_reason) lastFinishReason = choice.finish_reason;

                        if (!delta) continue;

                        if (typeof delta.content === 'string') {
                            accumulatedContent += delta.content;
                        }

                        if (Array.isArray(delta.images)) {
                            for (const img of delta.images) {
                                accumulatedImages.push(img);
                                log(`[IMG] üì• Received image chunk (type=${img?.type}, url_len=${img?.image_url?.url?.length || 0})`);
                            }
                        }

                        if (Array.isArray(delta.content)) {
                            for (const part of delta.content) {
                                if (part?.inline_data?.data) {
                                    accumulatedImages.push(part);
                                    log(`[IMG] üì• Received inline_data (${Math.round(part.inline_data.data.length / 1024)}KB)`);
                                } else if (part?.type === 'image_url' && part?.image_url?.url) {
                                    accumulatedImages.push(part);
                                    log(`[IMG] üì• Received image_url in content`);
                                }
                            }
                        }
                    } catch {
                        // Skip malformed JSON lines
                    }
                }
            }

            log(`[IMG] Stream complete: ${chunkCount} chunks, finish=${lastFinishReason}, text_len=${accumulatedContent.length}, images=${accumulatedImages.length}`);

            // ‚îÄ‚îÄ‚îÄ Extract image from accumulated data ‚îÄ‚îÄ‚îÄ
            if (accumulatedImages.length > 0) {
                const img = accumulatedImages[0];
                const url = img?.image_url?.url || img?.url || (typeof img === 'string' ? img : null);
                if (url) {
                    log(`[IMG] ‚úÖ Found image from stream (${url.substring(0, 60)}...)`);
                    return url;
                }
                if (img?.inline_data?.data) {
                    const mime = img.inline_data.mime_type || 'image/png';
                    log(`[IMG] ‚úÖ Found inline_data from stream (${mime})`);
                    return `data:${mime};base64,${img.inline_data.data}`;
                }
            }

            if (accumulatedContent.length > 0) {
                const base64Match = accumulatedContent.match(/data:image\/[^;]+;base64,[A-Za-z0-9+/=]+/);
                if (base64Match) {
                    log(`[IMG] ‚úÖ Found data URL in text content`);
                    return base64Match[0];
                }
            }

            log(`[IMG] ‚ö†Ô∏è No image in stream (attempt ${attempt}). text_preview: ${accumulatedContent.substring(0, 200)}`);
            continue;

        } catch (error: any) {
            const errMsg = error?.message || String(error);
            log(`[IMG] ‚ùå FAILED (attempt ${attempt}): ${errMsg}`);
            continue;
        }
    }
    log(`[IMG] ‚ùå All 3 attempts failed`);
    return null;
}

// ===================================================================
// MAIN HANDLER ‚Äî STREAMING NDJSON
// ===================================================================

export async function POST(
    request: NextRequest,
    { params }: { params: Promise<{ id: string }> }
) {
    const { id: campaignId } = await params;
    let body: any;
    try {
        body = await request.json();
    } catch {
        return new Response(
            JSON.stringify({ type: 'error', error: 'Invalid JSON body' }) + '\n',
            { status: 400, headers: { 'Content-Type': 'application/x-ndjson' } }
        );
    }

    const { genMode, winnerCaption, creativeBrief, winningPatterns, topAds, campaignName, topAdImageUrls } = body;

    if (!creativeBrief) {
        return new Response(
            JSON.stringify({ type: 'error', error: 'creativeBrief is required' }) + '\n',
            { status: 400, headers: { 'Content-Type': 'application/x-ndjson' } }
        );
    }

    const openrouterKey = process.env.OPENROUTER_API_KEY;
    if (!openrouterKey) {
        return new Response(
            JSON.stringify({ type: 'error', error: 'OPENROUTER_API_KEY not configured' }) + '\n',
            { status: 500, headers: { 'Content-Type': 'application/x-ndjson' } }
        );
    }

    const client = new OpenAI({
        apiKey: openrouterKey,
        baseURL: 'https://openrouter.ai/api/v1',
        defaultHeaders: {
            'HTTP-Referer': 'https://ads.supbaongu.vn',
            'X-Title': 'THO ADS AI - Creative Studio',
        },
    });

    const referenceUrls: string[] = topAdImageUrls || [];
    const mode = genMode || 'inspired';

    console.log(`[GENERATE_CREATIVE] üé® Campaign ${campaignId} ‚Äî STREAMING pipeline, mode = ${mode} `);
    console.log(`[GENERATE_CREATIVE] üìé Reference URLs count: ${referenceUrls.length} `);
    referenceUrls.forEach((url, i) => console.log(`[GENERATE_CREATIVE] üìé ref[${i}]: ${url.substring(0, 120)}...`));

    // Create streaming response
    const encoder = new TextEncoder();
    const stream = new ReadableStream({
        async start(controller) {
            const send = (data: any) => {
                controller.enqueue(encoder.encode(JSON.stringify(data) + '\n'));
            };

            try {
                // ‚îÄ‚îÄ‚îÄ STEP 1: Generate Caption + Image Prompts ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
                send({ type: 'step', message: 'ƒêang t·∫°o caption & image prompts...' });

                const captionPrompt = buildCaptionPrompt({
                    creativeBrief,
                    winningPatterns,
                    topAds,
                    campaignName,
                    genMode: mode,
                    winnerCaption: winnerCaption || '',
                }, mode === 'clone' ? referenceUrls.length : undefined, referenceUrls);

                // Build multimodal content: text prompt + reference images
                const captionContentParts: any[] = [{ type: 'text', text: captionPrompt }];
                if (referenceUrls.length > 0) {
                    referenceUrls.forEach((url, i) => {
                        captionContentParts.push({
                            type: 'text',
                            text: `\n[·∫¢nh tham kh·∫£o #${i + 1}]: `,
                        });
                        captionContentParts.push({
                            type: 'image_url',
                            image_url: { url },
                        });
                    });
                }

                const captionResponse = await client.chat.completions.create({
                    model: 'google/gemini-2.5-flash',
                    messages: [{ role: 'user', content: captionContentParts }],
                    temperature: 0.8,
                });

                const captionText = captionResponse.choices?.[0]?.message?.content || '';

                // Parse JSON from response
                let captionResult: {
                    caption: string;
                    imageCount: number;
                    imagePrompts: string[];
                    keyMessage: string;
                };

                try {
                    let cleaned = captionText;
                    const fenceMatch = cleaned.match(/```(?: json) ?\s *\n ? ([\s\S] *?) \n ?\s * ```/);
                    if (fenceMatch) cleaned = fenceMatch[1];
                    const startIdx = cleaned.indexOf('{');
                    if (startIdx === -1) throw new Error('No JSON object found');
                    let depth = 0;
                    let endIdx = -1;
                    for (let i = startIdx; i < cleaned.length; i++) {
                        if (cleaned[i] === '{') depth++;
                        else if (cleaned[i] === '}') { depth--; if (depth === 0) { endIdx = i; break; } }
                    }
                    if (endIdx === -1) throw new Error('Unbalanced JSON braces');
                    captionResult = JSON.parse(cleaned.substring(startIdx, endIdx + 1));
                } catch {
                    console.error('[GENERATE_CREATIVE] ‚ùå Failed to parse caption JSON:', captionText.slice(0, 500));
                    send({ type: 'error', error: 'AI tr·∫£ v·ªÅ format kh√¥ng h·ª£p l·ªá. Vui l√≤ng th·ª≠ l·∫°i.' });
                    controller.close();
                    return;
                }

                console.log(`[GENERATE_CREATIVE] ‚úÖ Caption generated, ${captionResult.imageCount} images requested`);

                // Stream caption result immediately
                send({
                    type: 'caption',
                    data: {
                        caption: captionResult.caption,
                        keyMessage: captionResult.keyMessage,
                        imageCount: captionResult.imageCount,
                        imagePrompts: captionResult.imagePrompts,
                        captionPrompt, // debug
                        referenceImageUrls: referenceUrls,
                    },
                });

                // ‚îÄ‚îÄ‚îÄ STEP 2: Send image plan (client will fetch images separately) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
                let effectiveImageCount: number;
                if (mode === 'clone' && referenceUrls.length > 0) {
                    effectiveImageCount = referenceUrls.length;
                } else {
                    effectiveImageCount = captionResult.imageCount;
                }

                const effectivePrompts = captionResult.imagePrompts.slice(0, effectiveImageCount);
                while (effectivePrompts.length < effectiveImageCount) {
                    effectivePrompts.push(captionResult.imagePrompts[captionResult.imagePrompts.length - 1] || captionResult.imagePrompts[0]);
                }

                // Build image plan: which prompt + which ref for each image
                const imagePlan: { prompt: string; referenceImageUrl: string | null }[] = [];
                for (let idx = 0; idx < effectiveImageCount; idx++) {
                    let refImage: string | null = null;
                    if (mode === 'clone') {
                        refImage = referenceUrls[idx] || null;
                    } else if (mode === 'inspired') {
                        refImage = referenceUrls[idx % referenceUrls.length] || null;
                    }
                    imagePlan.push({ prompt: effectivePrompts[idx], referenceImageUrl: refImage });
                }

                console.log(`[GENERATE_CREATIVE] üìã Image plan: ${effectiveImageCount} images, ${effectivePrompts.length} prompts`);

                // Send image plan to client ‚Äî client will call /generate-image for each
                send({
                    type: 'image_plan',
                    data: {
                        imageCount: effectiveImageCount,
                        images: imagePlan,
                    },
                });

                // ‚îÄ‚îÄ‚îÄ DONE ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
                send({ type: 'done' });
                console.log(`[GENERATE_CREATIVE] üéâ Streaming pipeline done`);

            } catch (error) {
                console.error('[GENERATE_CREATIVE] ‚ùå', error);
                send({ type: 'error', error: error instanceof Error ? error.message : 'Unknown error' });
            } finally {
                controller.close();
            }
        },
    });

    return new Response(stream, {
        headers: {
            'Content-Type': 'application/x-ndjson',
            'Cache-Control': 'no-cache',
            'Connection': 'keep-alive',
        },
    });
}
